*
# Limitations & Further Research

Due to how we compiled our data, we were not able to directly **compare the context of the posts**. Knowing the topics that the individual politicians discussed could explain many of the salient topics in the comment discourse, which is a key area we are missing. Furthermore, by restricting our dataset to only the top 10% most frequent words, we lost some nuances in the data that could have proven interesting. Some more manual input in cleaning our data would have been highly useful.


One particular disappointment in our research was that we could not do a **sentiment analysis**. After running the script, we found that the Italian language option was highly inaccurate. For example, some positive comments were labelled as negative and vice-versa, while some highly negative comments were labelled as neutral. A sentiment analysis regarding how users felt in their comments and how those differed between the politicians would have been particularly interesting. Below is a contingency matrix of the overall sentiment analysis, which does show some interesting trends. That said, due to the gross inaccuracy of the algorithm, commenting on it is not valuable.

<iframe class="scribd_iframe_embed" src="https://www.scribd.com/embeds/378745776/content?start_page=1&view_mode=scroll&access_key=key-IUllg9JTKAquHnuSisYN&show_recommendations=true" data-auto-height="false" data-aspect-ratio="1.3333333333333333" scrolling="no" id="doc_94742" width="100%" height="600" frameborder="0"></iframe>

Nonetheless, even this inability to incorporate a sentiment analysis - due to the experimental character of the study as a whole - contributes to future research. More specifically, these findings demonstrate key shortcomings of Italian language-based sentiment analysis algorithms, which could potentially serve as guiding points for developers and social scientists. 

In addition, a more targeted (mixed-methods) enquiry on **_comment discussions_** - that is, chain of comments and sub-comments, where users engage in political, economic or societal discussions - could yield more coherent and contextually-rich findings. Such an analysis would not only impose stricter limits and better control over datasets but may also be more susceptible to a more theoretical-based study of the linkages between social media discussions of wider societal shifts, users' behavior and political figures' effort to frame (or (de)stabilize) discursive agendas. This could also be complemented by an extensive topic modelling and sentiment network analysis of speeches and op-eds given by political figures.

Beyond digital public spaces, a discursive examination of dominant topics in traditional media, or a comparison of traditional and social media, might also shed light on new findings.



